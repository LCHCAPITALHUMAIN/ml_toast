{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUymE2l9GZfO"
      },
      "source": [
        "**Copyright 2023 Google LLC.**\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "JMyTNwSJGGWg"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSdRBuDb7jfh"
      },
      "source": [
        "<img align=\"left\" width=\"150\" src=\"https://services.google.com/fh/files/misc/ml_toast_logo.png\" alt=\"ml_toast_logo\" /><br><br>\n",
        "\n",
        "# üçû ML-ToAST: **M**ulti**l**ingual **To**pic Clustering of **A**ds-triggering **S**earch **T**erms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aYXRT3tCxJf"
      },
      "source": [
        "**Disclaimer: This is not an official Google product.**\n",
        "\n",
        "**üçû ML-ToAST** is an open-source tool that helps users cluster multilingual search terms captured from different time windows into semantically relevant topics. It helps advertisers / marketers surface insights related to changing consumer interest in a configurable, user-friendly, and privacy-safe manner.\n",
        "\n",
        "More information available at [github.com/google/ml_toast](https://github.com/google/ml_toast)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f4A-IWl37tK"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um6l3f0Rjm76"
      },
      "source": [
        "### Which search terms to use?\n",
        "\n",
        "We recommend extracting the Google Ads [Search Terms report](https://support.google.com/google-ads/answer/2472708) for the following periods:\n",
        " * **Last 30 days** (e.g. Nov 1 - Nov 30): it generally makes sense to look at the most recent search terms that triggered your ads.\n",
        " * **Previous 30/31 days** (e.g. Oct 1 - Oct 31): this helps provide information on those search terms that constitute your core business over those that are recently trending.\n",
        " * **Last 30 days last year** (e.g. Nov 1 - Nov 30 of the previous year): to account for seasonality effects (e.g. holiday season).\n",
        "\n",
        "We also recommend restricting the extracted search terms to a subset of *related* campaigns (e.g. all campaigns for a specific *product line* or *operating domain*) rather than all campaigns in your account. This allows the model to better capture how the search terms relate to one another, and therefore, extract more meaningful topics.\n",
        "\n",
        "The report can be downloaded from the Google Ads UI in CSV format and imported into a Google Sheets spreadsheet, to be used below for input/output.\n",
        "\n",
        "*Note: if you have multiple accounts operating under the same product line or domain, you can extract search terms from those accounts as well and group them all into the same Google Sheets spreadsheet.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HHBTlVl1zht"
      },
      "source": [
        "## Get Started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "krUBtMJeAQlf"
      },
      "outputs": [],
      "source": [
        "#@title Authenticate your user for this colab session\n",
        "import logging\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "logging.getLogger().setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ns6MdB_5OaZ8"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "!pip install tensorflow-text hdbscan umap-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJb_S6X0ILa2"
      },
      "source": [
        "## Input and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1ywOMopb0gUu"
      },
      "outputs": [],
      "source": [
        "#@title Configurable params { run: 'auto' }\n",
        "\n",
        "#@markdown Enter your spreadsheet ID:\n",
        "spreadsheet_id = \"id-goes-here\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the main worksheet name (which should usually contain the search terms from the last month):\n",
        "input_sheet_name = \"colab-input-main\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the prefix for any additional worksheets you would also like to analyze (e.g. search terms of the previous month, previous year, etc.):\n",
        "additional_sheets_prefix = \"colab-input-lookback-\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the name of the column that contains search terms. This value should be the same across all worksheets:\n",
        "search_terms_column = \"Search term\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown <hr>Filtering settings\n",
        "\n",
        "#@markdown ***Check*** the checkbox to filter on new terms (i.e. compare search terms from the aforementioned lookback worksheets) and ***uncheck*** to analyze search terms from the main worksheet only.\n",
        "filter_new_terms = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Enter the name of a column that contains a metric you would like to use for filtering and/or sorting (e.g. impressions):\n",
        "filter_metric_column = \"Impr.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Set this to filter terms with a *metric* (e.g. impressions) value lower than the input. Set to *-1* to skip filtering.\n",
        "filter_metric_max_threshold = -1 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Select the desired logical grouping (AND/OR) of the filters:\n",
        "filters_grouping = \"AND\" #@param [\"AND\", \"OR\"]\n",
        "\n",
        "#@markdown <hr>Advanced settings\n",
        "\n",
        "#@markdown Enter a comma-separated list of *stop words* which should be excluded from all generated topics:\n",
        "stop_words = \"stop1, stop2\" #@param {type:\"string\"}\n",
        "\n",
        "if stop_words:\n",
        "  stop_words = stop_words.replace(', ', ',').split(',')\n",
        "else:\n",
        "  stop_words = None\n",
        "\n",
        "#@markdown ***Check*** the checkbox to perform hyperparameter tuning for UMAP + HDBSCAN (increases processing time by a factor of ~3).<br>\n",
        "#@markdown Despite the time factor, we **highly** recommend using this to provide the optimal results for the given input.<br>\n",
        "#@markdown ***Uncheck*** to use the default clustering parameters.\n",
        "hyperparameter_tuning = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Google Ads specific params\n",
        "match_type_column = \"Match type\"\n",
        "match_type_broad = \"Broad match\"\n",
        "known_report_metrics = ['Clicks', 'Impr.', 'Cost']\n",
        "all_report_metrics = (\n",
        "    known_report_metrics if filter_metric_column in known_report_metrics\n",
        "    else [filter_metric_column])\n",
        "\n",
        "# Validation rules\n",
        "if not spreadsheet_id or not input_sheet_name or not search_terms_column:\n",
        "  raise ValueError(\n",
        "      'Invalid input! Please make sure at least '\n",
        "      '\"spreadsheet_id\", \"input_sheet_name\" and \"search_terms_column\" '\n",
        "      'are provided.')\n",
        "\n",
        "# Debugging params\n",
        "# Calculates performance metrics for the output topics, which will be done in\n",
        "# the provided LookerStudio dashboard (set to True if not using the dashboard)\n",
        "output_topic_metrics = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sC8BrKCh0QOC"
      },
      "outputs": [],
      "source": [
        "#@title Fetch data from the input spreadsheet\n",
        "#@markdown The first row in each worksheet will be considered the **column headers** row.\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "creds, _ = default()\n",
        "sheets_client = gspread.authorize(creds)\n",
        "spreadsheet = sheets_client.open_by_key(spreadsheet_id)\n",
        "\n",
        "input_values = spreadsheet.worksheet(input_sheet_name).get_all_values()\n",
        "additional_sheets_values = []\n",
        "\n",
        "if filter_new_terms and additional_sheets_prefix:\n",
        "  for sheet in spreadsheet.worksheets():\n",
        "    if sheet.title.startswith(additional_sheets_prefix):\n",
        "      additional_sheets_values.append(sheet.col_values(1))\n",
        "\n",
        "input_data = pd.DataFrame(input_values[1:], columns=input_values[0])\n",
        "\n",
        "for report_metric in all_report_metrics:\n",
        "  if report_metric in input_data.columns:\n",
        "    input_data[report_metric] = pd.to_numeric(\n",
        "        input_data[report_metric].str.replace(',', ''))\n",
        "\n",
        "print(\n",
        "    f'Worksheet: {input_sheet_name}\\nNumber of rows: {len(input_data)}\\n'\n",
        "    'First 5 rows:')\n",
        "input_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xD4cB0YElXtu"
      },
      "outputs": [],
      "source": [
        "#@title Extract search terms and apply the defined filters\n",
        "\n",
        "def add_filter(existing_filter, new_filter):\n",
        "  if filters_grouping == 'AND':\n",
        "    return existing_filter & new_filter\n",
        "  return existing_filter | new_filter\n",
        "\n",
        "additional_data = [\n",
        "    pd.DataFrame(sheet_values[1:], columns=[sheet_values[0]])\n",
        "    for sheet_values in additional_sheets_values]\n",
        "\n",
        "data_unfiltered = input_data.copy()\n",
        "\n",
        "series_filter = (filters_grouping == 'AND')\n",
        "applied_filters = []\n",
        "\n",
        "if additional_data:\n",
        "  data_unfiltered = (\n",
        "      data_unfiltered.merge(pd.concat(additional_data).drop_duplicates(),\n",
        "                    on=search_terms_column,\n",
        "                    how='left',\n",
        "                    indicator=True))\n",
        "  series_filter = add_filter(\n",
        "      existing_filter=series_filter, new_filter=(\n",
        "          data_unfiltered['_merge'] == 'left_only'))\n",
        "  applied_filters.append('filter_new_terms')\n",
        "\n",
        "if filter_metric_column and filter_metric_max_threshold > 0:\n",
        "  series_filter = add_filter(\n",
        "      existing_filter=series_filter, new_filter=(\n",
        "      data_unfiltered[filter_metric_column] <= filter_metric_max_threshold))\n",
        "  applied_filters.append(\n",
        "      f'filter_metric_max_threshold < {filter_metric_max_threshold}')\n",
        "\n",
        "filtered_data = (\n",
        "    data_unfiltered[series_filter] if applied_filters else data_unfiltered)\n",
        "\n",
        "if '_merge' in filtered_data.columns:\n",
        "  filtered_data = filtered_data.drop(columns='_merge')\n",
        "\n",
        "if filter_metric_column in filtered_data.columns:\n",
        "  filtered_data = filtered_data.sort_values(\n",
        "      by=filter_metric_column, ascending=False)\n",
        "\n",
        "print('\\n'.join([\n",
        "    f'Filtered data - total number of rows: {len(filtered_data)}',\n",
        "    f'Filters applied: {applied_filters}',\n",
        "    (\n",
        "        f\"Filters logical grouping: '{filters_grouping}'\"\n",
        "        if len(applied_filters) > 1 else ''),\n",
        "    'First 5 rows:']))\n",
        "filtered_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BisYiJXWlyM_"
      },
      "outputs": [],
      "source": [
        "#@title Extract 'Broad Match' and 'non Broad Match' terms from the filtered data\n",
        "\n",
        "if match_type_column in filtered_data.columns:\n",
        "  broad_match_terms = filtered_data.copy()\n",
        "  broad_match_terms = broad_match_terms[\n",
        "      filtered_data[match_type_column] == match_type_broad]\n",
        "\n",
        "  non_broad_match_terms = filtered_data.copy()\n",
        "  non_broad_match_terms = non_broad_match_terms[\n",
        "      filtered_data[match_type_column] != match_type_broad]\n",
        "\n",
        "  if filter_metric_column in filtered_data.columns:\n",
        "    broad_match_terms = broad_match_terms.sort_values(\n",
        "        by=filter_metric_column, ascending=False)\n",
        "    non_broad_match_terms = non_broad_match_terms.sort_values(\n",
        "        by=filter_metric_column, ascending=False)\n",
        "\n",
        "  broad_match_groups = {\n",
        "      'filtered_broad_match_terms': broad_match_terms,\n",
        "      'filtered_non_broad_match_terms': non_broad_match_terms,\n",
        "  }\n",
        "  print(\n",
        "      'Extracted:\\n'\n",
        "      f' - All terms where \"{match_type_column}\" is \"{match_type_broad}\" '\n",
        "      f'from the filtered data. Number of rows: {len(broad_match_terms)}')\n",
        "  print(\n",
        "      'Extracted:\\n'\n",
        "      f' - All terms where \"{match_type_column}\" is NOT \"{match_type_broad}\" '\n",
        "      f'from the filtered data. Number of rows: {len(non_broad_match_terms)}')\n",
        "else:\n",
        "  broad_match_groups = {}\n",
        "  print(\n",
        "      f'No column \"{match_type_column}\" found in the input data. '\n",
        "      'Skipping extraction of Broad Match terms.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aphRjaaviXKI"
      },
      "source": [
        "## Topic Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mtoxiM9RyVaV"
      },
      "outputs": [],
      "source": [
        "#@title Import the topic clustering library\n",
        "!echo \"Restoring working directory to root...\"\n",
        "%cd /content\n",
        "!rm -rf ml_toast && git clone https://github.com/google/ml_toast.git\n",
        "!echo \"Changing working directory to ml_toast...\"\n",
        "%cd ml_toast\n",
        "\n",
        "from ml_toast import topic_clustering as topic_clustering_lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qcgsRGcg0maR"
      },
      "outputs": [],
      "source": [
        "#@title Use the library to determine topics for all input groups\n",
        "terms_input_data_dict = {'filtered_terms': filtered_data}\n",
        "for key, broad_match_group in broad_match_groups.items():\n",
        "  terms_input_data_dict[key] = broad_match_group\n",
        "\n",
        "for key, terms_input_data in terms_input_data_dict.items():\n",
        "  topic_clustering = topic_clustering_lib.TopicClustering(\n",
        "      data_id=key,\n",
        "      input_col=search_terms_column,\n",
        "      stop_words=stop_words,\n",
        "      do_hdbscan_hyperopt=hyperparameter_tuning)\n",
        "  topics_kmeans, topics_hdbscan = topic_clustering.determine_topics(\n",
        "      terms_input_data)\n",
        "  terms_input_data['Topic'] = topics_kmeans\n",
        "  terms_input_data['Additional Topics'] = topics_hdbscan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZupJfkwIHml"
      },
      "source": [
        "## Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UEs6V8SS4xSb"
      },
      "outputs": [],
      "source": [
        "#@title Write results back to the input spreadsheet\n",
        "#@markdown New worksheets with the prefix **colab-** will be appended to the spreadsheet,\n",
        "#@markdown or overwritten if they already exist.\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "for key, terms_input_data in terms_input_data_dict.items():\n",
        "  try:\n",
        "    output_sheet = spreadsheet.worksheet(f'colab-{key}-output')\n",
        "    output_sheet.clear()\n",
        "  except gspread.exceptions.WorksheetNotFound:\n",
        "    output_sheet = spreadsheet.add_worksheet(\n",
        "        f'colab-{key}-output',\n",
        "        rows=len(terms_input_data),\n",
        "        cols=len(terms_input_data.columns))\n",
        "  set_with_dataframe(\n",
        "      output_sheet, terms_input_data, include_column_header=True)\n",
        "\n",
        "  if output_topic_metrics:\n",
        "    for topics_type in ['Topic', 'Additional Topics']:\n",
        "      cluster_metrics = pd.DataFrame()\n",
        "      cluster_metrics['Topic'] = terms_input_data[topics_type]\n",
        "      for report_metric in all_report_metrics:\n",
        "        if report_metric in terms_input_data.columns:\n",
        "          cluster_metrics[report_metric] = terms_input_data[report_metric]\n",
        "\n",
        "      cluster_metrics = cluster_metrics.groupby(by='Topic', sort=False).agg(\n",
        "          ['mean', 'median', 'min', 'max', 'std', 'var'])\n",
        "      cluster_metrics.insert(loc=0, column='Topic', value=cluster_metrics.index)\n",
        "      cluster_metrics.insert(\n",
        "          loc=1,\n",
        "          column='Count',\n",
        "          value=terms_input_data.groupby(by=topics_type, sort=False).count()[\n",
        "              search_terms_column])\n",
        "      cluster_metrics = cluster_metrics.sort_values(by='Count', ascending=False)\n",
        "      cluster_metrics_key = (\n",
        "          f\"{key}_{topics_type.lower().replace(' ', '_')}\")\n",
        "\n",
        "      try:\n",
        "        metrics_sheet = spreadsheet.worksheet(\n",
        "            f'colab-{cluster_metrics_key}-metrics')\n",
        "        metrics_sheet.clear()\n",
        "      except gspread.exceptions.WorksheetNotFound:\n",
        "        metrics_sheet = spreadsheet.add_worksheet(\n",
        "            f'colab-{cluster_metrics_key}-metrics',\n",
        "            rows=len(cluster_metrics),\n",
        "            cols=len(cluster_metrics.columns))\n",
        "      set_with_dataframe(\n",
        "          metrics_sheet, cluster_metrics, include_column_header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l-ceTbYbfV-"
      },
      "source": [
        "### Visualize the generated topics in LookerStudio\n",
        "\n",
        "ML-Toast provides a template LookerStudio dashboard to help you visualize the generated topics and quickly surface insights.\n",
        "\n",
        "Use [this link](https://lookerstudio.google.com/c/u/0/reporting/8bc2240e-a919-4916-9c7f-daf72f75bf42/preview) to create a copy of the dashboard and get started! All you would need to do is map the data sources used by the dashboard to the spreadsheet used for the input / output above."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9f4A-IWl37tK"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
